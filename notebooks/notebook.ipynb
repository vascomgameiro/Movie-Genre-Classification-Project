{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurate Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\vasco\\repos\\Natural-Language\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = \"C:/Users/vasco/repos/Natural-Language\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from src.dataset import read_data\n",
    "\n",
    "path = \"data/raw/train.txt\"\n",
    "columns = [\"title\", \"from\", \"genre\", \"director\", \"description\"]\n",
    "\n",
    "df = read_data(path, columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Prof. Ajoy Mukherjee” and his spouse “Aditi” witness a murder, committed by the vociferous criminal “Digbijay”. In spite of repeated warnings from “Digbijay” and his right hand “Loha” the Professors give witness against them and they go to jail for 7 years. After coming out Djgbibay turns out to be even stronger. He attacks Ajoy’s family. He sends a man called “Binod Sharma” who pretends to be the friend of Joy (Ajoy’s brother). Digbijay and Binod conspire against Joy and Ajoy. After sending his own man to rob Joy of two lack rupees, Binod compels Joy to do a murder. In the meantime Digbijay stabs Ajoy and Joy gets entangled for the murder of his brother. A local inspector Dilip Lahiri also turns out to be a peer of Digbijay. While Joy remains in police custody, Digbijay tactically rapes and murders Joy’s younger sister Dia. After all these incidents Joy’s sister-in-law Aditi commits suicide. Joy teams up with his friend Kanchan and Kumar to seek revenge killing Binod, Dilip, Loha and Digbijay one after the other. Joy and his friends are jailed for 5 years.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Impressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "print(df.info())\n",
    "print(\"*\" * 20)\n",
    "repeated_titles = df[\"title\"].value_counts()[df[\"title\"].value_counts() > 1].head(5)\n",
    "print(repeated_titles)\n",
    "print(\"*\" * 20)\n",
    "popular_directors = df[\"director\"].value_counts().head(5)\n",
    "print(popular_directors)\n",
    "print(\"*\" * 20)\n",
    "print(df[\"from\"].value_counts().head(5))\n",
    "print(\"*\" * 20)\n",
    "print(\"Number of duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>from</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>At Gunpoint</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Alfred L. Werker</td>\n",
       "      <td>Plainview is a peaceful town, all the better f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>At Gunpoint</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Alfred L. Werker</td>\n",
       "      <td>Plainview is a peaceful town, all the better f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>Black Rock</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>Katie Aselton</td>\n",
       "      <td>Sarah (Kate Bosworth) invites her childhood fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>Black Rock</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>Katie Aselton</td>\n",
       "      <td>Sarah (Kate Bosworth) invites her childhood fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>Captain America</td>\n",
       "      <td>American</td>\n",
       "      <td>action</td>\n",
       "      <td>Albert Pyun</td>\n",
       "      <td>In Fascist Italy in 1936, the government kidna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>Captain America</td>\n",
       "      <td>American</td>\n",
       "      <td>action</td>\n",
       "      <td>Albert Pyun</td>\n",
       "      <td>In Fascist Italy in 1936, the government kidna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Creep</td>\n",
       "      <td>British</td>\n",
       "      <td>horror</td>\n",
       "      <td>Christopher Smith</td>\n",
       "      <td>Arthur (Ken Campbell) and George (Vas Blackwoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>Creep</td>\n",
       "      <td>British</td>\n",
       "      <td>horror</td>\n",
       "      <td>Christopher Smith</td>\n",
       "      <td>Arthur (Ken Campbell) and George (Vas Blackwoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>Drive-In Massacre</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>Stu Segall</td>\n",
       "      <td>A couple go to a drive-in theater in a rural C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>Drive-In Massacre</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>Stu Segall</td>\n",
       "      <td>A couple go to a drive-in theater in a rural C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>Flesh and the Spur</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Edward L. Cahn</td>\n",
       "      <td>Tanner is a desperate prisoner who escapes fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>Flesh and the Spur</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Edward L. Cahn</td>\n",
       "      <td>Tanner is a desperate prisoner who escapes fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>Leo the Last</td>\n",
       "      <td>British</td>\n",
       "      <td>drama</td>\n",
       "      <td>John Boorman</td>\n",
       "      <td>The ennui-afflicted heir to a deposed European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>Leo the Last</td>\n",
       "      <td>British</td>\n",
       "      <td>drama</td>\n",
       "      <td>John Boorman</td>\n",
       "      <td>The ennui-afflicted heir to a deposed European...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>More Dead Than Alive</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Robert Sparr</td>\n",
       "      <td>A murderer named Cain (Clint Walker) is releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7692</th>\n",
       "      <td>More Dead Than Alive</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>Robert Sparr</td>\n",
       "      <td>A murderer named Cain (Clint Walker) is releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Now or Never</td>\n",
       "      <td>American</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Fred C. Newmeyer, Hal Roach</td>\n",
       "      <td>A young woman, who is employed as a nanny to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>Now or Never</td>\n",
       "      <td>American</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Fred C. Newmeyer, Hal Roach</td>\n",
       "      <td>A young woman, who is employed as a nanny to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>Planet of Dinosaurs</td>\n",
       "      <td>American</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>James Shea</td>\n",
       "      <td>After a mechanical failure aboard the spaceshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>Planet of Dinosaurs</td>\n",
       "      <td>American</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>James Shea</td>\n",
       "      <td>After a mechanical failure aboard the spaceshi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title      from    genre                     director  \\\n",
       "7102           At Gunpoint  American  western             Alfred L. Werker   \n",
       "4053           At Gunpoint  American  western             Alfred L. Werker   \n",
       "3121            Black Rock  American   horror                Katie Aselton   \n",
       "4714            Black Rock  American   horror                Katie Aselton   \n",
       "6456       Captain America  American   action                  Albert Pyun   \n",
       "6285       Captain America  American   action                  Albert Pyun   \n",
       "226                  Creep   British   horror            Christopher Smith   \n",
       "4126                 Creep   British   horror            Christopher Smith   \n",
       "6576     Drive-In Massacre  American   horror                   Stu Segall   \n",
       "4563     Drive-In Massacre  American   horror                   Stu Segall   \n",
       "3527    Flesh and the Spur  American  western               Edward L. Cahn   \n",
       "4573    Flesh and the Spur  American  western               Edward L. Cahn   \n",
       "6618          Leo the Last   British    drama                 John Boorman   \n",
       "5032          Leo the Last   British    drama                 John Boorman   \n",
       "7474  More Dead Than Alive  American  western                 Robert Sparr   \n",
       "7692  More Dead Than Alive  American  western                 Robert Sparr   \n",
       "555           Now or Never  American   comedy  Fred C. Newmeyer, Hal Roach   \n",
       "5773          Now or Never  American   comedy  Fred C. Newmeyer, Hal Roach   \n",
       "4803   Planet of Dinosaurs  American   sci-fi                   James Shea   \n",
       "3280   Planet of Dinosaurs  American   sci-fi                   James Shea   \n",
       "\n",
       "                                            description  \n",
       "7102  Plainview is a peaceful town, all the better f...  \n",
       "4053  Plainview is a peaceful town, all the better f...  \n",
       "3121  Sarah (Kate Bosworth) invites her childhood fr...  \n",
       "4714  Sarah (Kate Bosworth) invites her childhood fr...  \n",
       "6456  In Fascist Italy in 1936, the government kidna...  \n",
       "6285  In Fascist Italy in 1936, the government kidna...  \n",
       "226   Arthur (Ken Campbell) and George (Vas Blackwoo...  \n",
       "4126  Arthur (Ken Campbell) and George (Vas Blackwoo...  \n",
       "6576  A couple go to a drive-in theater in a rural C...  \n",
       "4563  A couple go to a drive-in theater in a rural C...  \n",
       "3527  Tanner is a desperate prisoner who escapes fro...  \n",
       "4573  Tanner is a desperate prisoner who escapes fro...  \n",
       "6618  The ennui-afflicted heir to a deposed European...  \n",
       "5032  The ennui-afflicted heir to a deposed European...  \n",
       "7474  A murderer named Cain (Clint Walker) is releas...  \n",
       "7692  A murderer named Cain (Clint Walker) is releas...  \n",
       "555   A young woman, who is employed as a nanny to a...  \n",
       "5773  A young woman, who is employed as a nanny to a...  \n",
       "4803  After a mechanical failure aboard the spaceshi...  \n",
       "3280  After a mechanical failure aboard the spaceshi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(keep=False)].sort_values(\"title\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.plots import plot_movie_data\n",
    "\n",
    "plot_movie_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.plots import plot_stopword_frequency\n",
    "\n",
    "plot_stopword_frequency(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stopword_frequency(df, \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.plots import get_text_statistics\n",
    "\n",
    "stats = get_text_statistics(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.plots import plot_histograms\n",
    "\n",
    "plot_histograms(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.plots import plot_boxplots\n",
    "\n",
    "plot_boxplots(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.plots import plot_correlation_matrix, apply_pca\n",
    "\n",
    "# Standardize the data outside the PCA function\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(stats)\n",
    "\n",
    "plot_correlation_matrix(stats)\n",
    "pca_df, pca = apply_pca(scaled_data, df[\"genre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>from</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>Black Dalia</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>action</td>\n",
       "      <td>Baburaj</td>\n",
       "      <td>A student of Sacred Heart Medical College is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>Anthima Theerpu</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>action</td>\n",
       "      <td>A.D.V. Babu Raj</td>\n",
       "      <td>A student of Sacred Heart Medical College is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Bhayya</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>action</td>\n",
       "      <td>Boopathy Pandian</td>\n",
       "      <td>Anbu (Vishal) is a happy-go-lucky engineering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>Malaikottai</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>action</td>\n",
       "      <td>Boopathy Pandian</td>\n",
       "      <td>Anbu (Vishal) is a happy-go-lucky engineering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>The Protector</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>action</td>\n",
       "      <td>James Glickenhaus</td>\n",
       "      <td>As noted above, Jackie Chan re-edited The Prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>Protector, The</td>\n",
       "      <td>American</td>\n",
       "      <td>action</td>\n",
       "      <td>James Glickenhaus</td>\n",
       "      <td>As noted above, Jackie Chan re-edited The Prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>36 Hours</td>\n",
       "      <td>British</td>\n",
       "      <td>crime</td>\n",
       "      <td>Montgomery Tully</td>\n",
       "      <td>Bill Rogers (Dan Duryea), an American jet pilo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Terror Street</td>\n",
       "      <td>American</td>\n",
       "      <td>crime</td>\n",
       "      <td>Montgomery Tully</td>\n",
       "      <td>Bill Rogers (Dan Duryea), an American jet pilo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>Harry Tracy</td>\n",
       "      <td>American</td>\n",
       "      <td>western</td>\n",
       "      <td>William A. Graham</td>\n",
       "      <td>By the end of the 19th century, Butch Cassidy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>Harry Tracy, Desperado</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>western</td>\n",
       "      <td>William Graham</td>\n",
       "      <td>By the end of the 19th century, Butch Cassidy,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title       from    genre           director  \\\n",
       "5748             Black Dalia  Malayalam   action            Baburaj   \n",
       "4030         Anthima Theerpu     Telugu   action    A.D.V. Babu Raj   \n",
       "435                   Bhayya     Telugu   action   Boopathy Pandian   \n",
       "7436             Malaikottai      Tamil   action   Boopathy Pandian   \n",
       "3028           The Protector  Hong Kong   action  James Glickenhaus   \n",
       "7711          Protector, The   American   action  James Glickenhaus   \n",
       "3038                36 Hours    British    crime   Montgomery Tully   \n",
       "2445           Terror Street   American    crime   Montgomery Tully   \n",
       "6780             Harry Tracy   American  western  William A. Graham   \n",
       "1452  Harry Tracy, Desperado   Canadian  western     William Graham   \n",
       "\n",
       "                                            description  \n",
       "5748  A student of Sacred Heart Medical College is f...  \n",
       "4030  A student of Sacred Heart Medical College is f...  \n",
       "435   Anbu (Vishal) is a happy-go-lucky engineering ...  \n",
       "7436  Anbu (Vishal) is a happy-go-lucky engineering ...  \n",
       "3028  As noted above, Jackie Chan re-edited The Prot...  \n",
       "7711  As noted above, Jackie Chan re-edited The Prot...  \n",
       "3038  Bill Rogers (Dan Duryea), an American jet pilo...  \n",
       "2445  Bill Rogers (Dan Duryea), an American jet pilo...  \n",
       "6780  By the end of the 19th century, Butch Cassidy,...  \n",
       "1452  By the end of the 19th century, Butch Cassidy,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.dataset import filter_duplicate_descriptions\n",
    "\n",
    "filter_duplicate_descriptions(df, \"description\", \"title\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.dataset import find_similar_descriptions\n",
    "\n",
    "similar_pairs = find_similar_descriptions(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Different Title: \n",
      "\n",
      "Neevalle Neevalle (95) and Unnale Unnale (1641) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Little Big Horn (819) and The Fighting Seventh (1009) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Nayagi (2307) and Nayaki (2316) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "\n",
      "\n",
      "\n",
      " Different Director: \n",
      "\n",
      "Glenn Chaika (1517) and Glenn Chaika, Kelvin Lee (1760) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Glenn Chaika (1517) and Glenn Chaika, Kelvin Lee (2215) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Govi (2307) and Goverdhan Reddy (2316) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "\n",
      "\n",
      "\n",
      " Different Genre: \n",
      "\n",
      "comedy (923) and crime (1591) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "sci-fi (1517) and animation (1760) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "sci-fi (1517) and animation (2215) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "\n",
      "\n",
      "\n",
      " Different From: \n",
      "\n",
      "Telugu (95) and Tamil (1641) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Chinese (1517) and American (1760) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "American (1760) and Chinese (2215) : (Cosine 1.0000, Jaccard 1.0000)\n",
      "Tamil (2307) and Telugu (2316) : (Cosine 1.0000, Jaccard 1.0000)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from src.dataset import print_differences\n",
    "\n",
    "print_differences(df, similar_pairs, \"title\")\n",
    "print(\"\\n\")\n",
    "print_differences(df, similar_pairs, \"director\")\n",
    "print(\"\\n\")\n",
    "print_differences(df, similar_pairs, \"genre\")\n",
    "print(\"\\n\")\n",
    "print_differences(df, similar_pairs, \"from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process  # Using rapidfuzz for fast fuzzy matching\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def preprocess_and_find_merge_candidates(df, director_column, threshold=85):\n",
    "    \"\"\"\n",
    "    Preprocesses director names and finds candidates for merging based on fuzzy matching.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The original DataFrame containing director names.\n",
    "    director_column (str): The column name containing the director names.\n",
    "    threshold (int): Similarity score threshold for fuzzy matching (default: 85).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with potential merge candidates based on the similarity score,\n",
    "                  including the original director names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Preprocess the names (lowercase, normalize, and strip extra spaces)\n",
    "    def preprocess_name(name):\n",
    "        # Normalize and remove accents\n",
    "        name = unicodedata.normalize(\"NFKD\", name).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "        # Remove extra spaces and commas, convert to lowercase\n",
    "        name = re.sub(r\"\\s+\", \" \", name.strip())  # Replace multiple spaces with single space\n",
    "        name = re.sub(r\"[^\\w\\s,]\", \"\", name)  # Remove special characters, keep commas\n",
    "\n",
    "        # Remove single or double initials (e.g., \"M.\", \"R A\", \"S.\")\n",
    "        name = re.sub(r\"\\b(?:[A-Z](?:\\.|\\s)){1,2}\\b\", \"\", name)  # Matches 1 or 2 initials with/without period\n",
    "\n",
    "        return name.lower()\n",
    "\n",
    "    # Step 2: Preprocess and split multiple names in the column\n",
    "    df_temp = df.copy()  # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_temp[\"processed_name\"] = df_temp[director_column].apply(preprocess_name)\n",
    "    df_temp[\"split_names\"] = df_temp[\"processed_name\"].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "    # Track the original names before exploding\n",
    "    df_temp[\"original_name\"] = df[director_column]\n",
    "\n",
    "    # Explode the DataFrame so that each name is on a separate row\n",
    "    df_exploded = df_temp.explode(\"split_names\")\n",
    "    df_exploded[\"split_names\"] = df_exploded[\"split_names\"].str.strip()  # Strip extra spaces\n",
    "\n",
    "    # Step 3: Define a function to find candidates for merging using fuzzy matching\n",
    "    def find_merge_candidates(df, threshold=85):\n",
    "        \"\"\"\n",
    "        Finds names that are candidates for merging based on fuzzy matching.\n",
    "        \"\"\"\n",
    "        names = df[\"split_names\"].unique()\n",
    "        merge_candidates = []\n",
    "\n",
    "        for name in names:\n",
    "            # Get a list of all potential matches that exceed the threshold\n",
    "            matches = process.extract(name, names, scorer=fuzz.ratio, limit=None)\n",
    "            for match_name, score, _ in matches:  # Here we unpack the third value but ignore it\n",
    "                if name != match_name and score >= threshold:\n",
    "                    original_name = df[df[\"split_names\"] == name][\"original_name\"].values[0]\n",
    "                    potential_merge_original = df[df[\"split_names\"] == match_name][\"original_name\"].values[0]\n",
    "                    merge_candidates.append((original_name, name, potential_merge_original, match_name, score))\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            merge_candidates,\n",
    "            columns=[\n",
    "                \"Original Name\",\n",
    "                \"Processed Name\",\n",
    "                \"Potential Merge Original\",\n",
    "                \"Potential Merge Processed\",\n",
    "                \"Similarity Score\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Step 4: Get the merge candidates DataFrame\n",
    "    merge_candidates_df = find_merge_candidates(df_exploded, threshold)\n",
    "\n",
    "    # Step 5: Sort the results for better readability\n",
    "    merge_candidates_df.sort_values(by=\"Similarity Score\", ascending=False, inplace=True)\n",
    "\n",
    "    return merge_candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_candidates = preprocess_and_find_merge_candidates(df, \"director\", threshold=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_candidates.loc[:, [\"Original Name\", \"Potential Merge Original\", \"Similarity Score\"]].iloc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"director\"] == \"Mrighdeep Singh Lamba\") | (df[\"director\"] == \"Mrigdeep Singh Lamba\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def clean_director_name(name: str):\n",
    "    name = name.lower().replace(\" \", \"\").replace(\"-\", \"\")\n",
    "    return re.sub(r\"\\.\", \"\", name)\n",
    "\n",
    "\n",
    "def create_name_map(df: pd.DataFrame):\n",
    "    name_map = defaultdict(set)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        director_list = [name.strip() for name in row[\"director\"].split(\",\")]\n",
    "\n",
    "        for director in director_list:\n",
    "            cleaned_name = clean_director_name(director)\n",
    "            name_map[cleaned_name].add(director)\n",
    "\n",
    "    return name_map\n",
    "\n",
    "\n",
    "director_name_map = create_name_map(df)\n",
    "filtered_name_map = {key: value for key, value in director_name_map.items() if len(value) > 1}\n",
    "\n",
    "\n",
    "print(\"Directors with more than 1 value:\")\n",
    "filtered_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.loc[df[\"director\"] == \"3 directors\" \"Director\"] = np.nan\n",
    "df.loc[:, \"director\"] = df.loc[:, \"director\"].replace(\"Unknown\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (NEEDS WORK!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.dataset import lemmatize_tokens, extract_noun_phrases, word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence: str) -> str:\n",
    "    \"\"\"Preprocess the sentence by tokenizing, lemmatizing, and joining noun phrases.\"\"\"\n",
    "    cleaned_sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    tokens = word_tokenize(cleaned_sentence)\n",
    "    noun_phrases = extract_noun_phrases(sentence)\n",
    "    noun_phrases_joined = [\"\".join(phrase.split()) for phrase in noun_phrases]\n",
    "    lemmatized_tokens = lemmatize_tokens(tokens)\n",
    "    combined_tokens = list(set(lemmatized_tokens + noun_phrases_joined))\n",
    "    return \" \".join(combined_tokens)\n",
    "\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(preprocess_sentence)\n",
    "df[\"description\"] = df[\"description\"].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"] = df[\"from\"].map(\n",
    "    {\n",
    "        \"American\": \"Western\",\n",
    "        \"British\": \"Western\",\n",
    "        \"Canadian\": \"Western\",\n",
    "        \"Australian\": \"Western\",\n",
    "        \"Bollywood\": \"South Asian\",\n",
    "        \"Telugu\": \"South Asian\",\n",
    "        \"Tamil\": \"South Asian\",\n",
    "        \"Malayalam\": \"South Asian\",\n",
    "        \"Bengali\": \"South Asian\",\n",
    "        \"Kannada\": \"South Asian\",\n",
    "        \"Marathi\": \"South Asian\",\n",
    "        \"Punjabi\": \"South Asian\",\n",
    "        \"Assamese\": \"South Asian\",\n",
    "        \"Chinese\": \"East Asian\",\n",
    "        \"Japanese\": \"East Asian\",\n",
    "        \"South_Korean\": \"East Asian\",\n",
    "        \"Hong Kong\": \"East Asian\",\n",
    "        \"Filipino\": \"Southeast Asian\",\n",
    "        \"Bangladeshi\": \"South Asian\",\n",
    "        \"Russian\": \"European\",\n",
    "        \"Turkish\": \"Middle Eastern\",\n",
    "        \"Egyptian\": \"Middle Eastern\",\n",
    "        \"Malaysian\": \"Southeast Asian\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.logratioanalysis import LogRatioAnalysis\n",
    "\n",
    "logratio_title = LogRatioAnalysis(df, \"title\", \"genre\")\n",
    "logratio_description = LogRatioAnalysis(df, \"description\", \"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from src.logratioanalysis import plot_scree_subplots_for_genres\n",
    "\n",
    "genres = df.genre.unique()\n",
    "plot_scree_subplots_for_genres(logratio_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "plot_scree_subplots_for_genres(logratio_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "description_tokens = logratio_description.feature_selection(25000)\n",
    "title_tokens = logratio_title.feature_selection(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "def select_tokens(text, selected_tokens, tokenizer=nltk.word_tokenize):\n",
    "    \"\"\"\n",
    "    Cleans a single document by keeping only the tokens present in the selected_tokens set.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text document to clean.\n",
    "    selected_tokens (set or list): The set or list of tokens to retain in the text.\n",
    "    tokenizer (function): A function to tokenize the text (defaults to nltk.word_tokenize).\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned text with only the selected tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        tokens = tokenizer(text)\n",
    "        filtered_tokens = [token for token in tokens if token in selected_tokens]\n",
    "        return \" \".join(filtered_tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Didn't Work :')\n",
    "# df['cleaned_description'] = df[\"description\"].apply(select_tokens, selected_tokens=description_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"genre\"] = label_encoder.fit_transform(df[\"genre\"])\n",
    "df[\"director\"] = df[\"director\"].fillna(\"\")\n",
    "\n",
    "X_train = df.drop(\"genre\", axis=1)\n",
    "y_train = df[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from skrub import SelectCols, SimilarityEncoder\n",
    "\n",
    "text_pipeline = make_union(\n",
    "    make_pipeline(\n",
    "        ColumnSelector(\"title\", drop_axis=True),\n",
    "        TfidfVectorizer(ngram_range=(2, 4)),\n",
    "        StandardScaler(with_mean=False),\n",
    "        TruncatedSVD(),\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        ColumnSelector(\"description\", drop_axis=True),\n",
    "        TfidfVectorizer(),\n",
    "        StandardScaler(with_mean=False),\n",
    "        TruncatedSVD(),\n",
    "    ),\n",
    "    make_pipeline(SelectCols(\"region\"), SimilarityEncoder()),\n",
    "    make_pipeline(SelectCols(\"from\"), OneHotEncoder(sparse_output=False)),\n",
    "    make_pipeline(\n",
    "        ColumnSelector(\"director\", drop_axis=True),\n",
    "        TfidfVectorizer(ngram_range=(1, 2)),  #\n",
    "        StandardScaler(with_mean=False),\n",
    "        TruncatedSVD(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(text_pipeline, HistGradientBoostingClassifier())\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Update param_distributions to match HistGradientBoostingClassifier\n",
    "param_distributions = {\n",
    "    \"histgradientboostingclassifier__learning_rate\": loguniform(0.03, 0.07),\n",
    "    \"histgradientboostingclassifier__max_iter\": randint(250, 350),\n",
    "    \"histgradientboostingclassifier__max_depth\": randint(4, 6),\n",
    "    \"histgradientboostingclassifier__min_samples_leaf\": randint(85, 95),\n",
    "    \"histgradientboostingclassifier__max_leaf_nodes\": randint(120, 140),\n",
    "    \"histgradientboostingclassifier__l2_regularization\": loguniform(0.0005, 0.003),\n",
    "    \"featureunion__pipeline-1__truncatedsvd__n_components\": randint(200, 400),\n",
    "    \"featureunion__pipeline-2__truncatedsvd__n_components\": randint(2000, 4000),\n",
    "    \"featureunion__pipeline-5__truncatedsvd__n_components\": randint(200, 400),\n",
    "}\n",
    "\n",
    "# Set up the RandomizedSearchCV with the updated parameters\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    verbose=4,\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV with the updated pipeline\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters, score, and model\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"\\n Best Parameters:\", best_params)\n",
    "print(\"\\n Best Score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
